{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# In this notebook a simple Q learner will be trained and evaluated. The Q learner recommends when to buy or sell shares of one particular stock, and in which quantity (in fact it determines the desired fraction of shares in the total portfolio value). One initial attempt was made to train the Q-learner with multiple processes, but it was unsuccessful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import scipy.optimize as spo\n",
    "import sys\n",
    "from time import time\n",
    "from sklearn.metrics import r2_score, median_absolute_error\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "import recommender.simulator as sim\n",
    "from utils.analysis import value_eval\n",
    "from recommender.agent import Agent\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_THREADS = 1\n",
    "LOOKBACK = 252*2 + 28\n",
    "STARTING_DAYS_AHEAD = 20\n",
    "POSSIBLE_FRACTIONS = [0.0, 1.0]\n",
    "\n",
    "# Get the data\n",
    "SYMBOL = 'SPY'\n",
    "total_data_train_df = pd.read_pickle('../../data/data_train_val_df.pkl').stack(level='feature')\n",
    "data_train_df = total_data_train_df[SYMBOL].unstack()\n",
    "total_data_test_df = pd.read_pickle('../../data/data_test_df.pkl').stack(level='feature')\n",
    "data_test_df = total_data_test_df[SYMBOL].unstack()\n",
    "if LOOKBACK == -1:\n",
    "    total_data_in_df = total_data_train_df\n",
    "    data_in_df = data_train_df\n",
    "else:\n",
    "    data_in_df = data_train_df.iloc[-LOOKBACK:]\n",
    "    total_data_in_df = total_data_train_df.loc[data_in_df.index[0]:]\n",
    "\n",
    "# Create many agents\n",
    "index = np.arange(NUM_THREADS).tolist()\n",
    "env, num_states, num_actions = sim.initialize_env(total_data_in_df, \n",
    "                                                  SYMBOL, \n",
    "                                                  starting_days_ahead=STARTING_DAYS_AHEAD,\n",
    "                                                  possible_fractions=POSSIBLE_FRACTIONS)\n",
    "agents = [Agent(num_states=num_states, \n",
    "                num_actions=num_actions, \n",
    "                random_actions_rate=0.98, \n",
    "                random_actions_decrease=0.9999,\n",
    "                dyna_iterations=0,\n",
    "                name='Agent_{}'.format(i)) for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_results(results_list, data_in_df, graph=False):\n",
    "    for values in results_list:\n",
    "        total_value = values.sum(axis=1)\n",
    "        print('Sharpe ratio: {}\\nCum. Ret.: {}\\nAVG_DRET: {}\\nSTD_DRET: {}\\nFinal value: {}'.format(*value_eval(pd.DataFrame(total_value))))\n",
    "        print('-'*100)\n",
    "        initial_date = total_value.index[0]\n",
    "        compare_results = data_in_df.loc[initial_date:, 'Close'].copy()\n",
    "        compare_results.name = SYMBOL\n",
    "        compare_results_df = pd.DataFrame(compare_results)\n",
    "        compare_results_df['portfolio'] = total_value\n",
    "        std_comp_df = compare_results_df / compare_results_df.iloc[0]\n",
    "        if graph:\n",
    "            plt.figure()\n",
    "            std_comp_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's show the symbols data, to see how good the recommender has to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe ratio: 1.601691549431671\n",
      "Cum. Ret.: 0.4244923418116293\n",
      "AVG_DRET: 0.0007179294312480581\n",
      "STD_DRET: 0.00711546265440581\n",
      "Final value: 205.54\n"
     ]
    }
   ],
   "source": [
    "print('Sharpe ratio: {}\\nCum. Ret.: {}\\nAVG_DRET: {}\\nSTD_DRET: {}\\nFinal value: {}'.format(*value_eval(pd.DataFrame(data_in_df['Close'].iloc[STARTING_DAYS_AHEAD:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation for agent: Agent_0. 512 days of simulation to go.\n",
      "Date 2013-05-02 00:00:00 (simulating until 2014-12-31 00:00:00).  Time: 0.31346774101257324s.  Value: 10319.259999999997."
     ]
    }
   ],
   "source": [
    "# Simulate (with new envs, each time)\n",
    "n_epochs = 15\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    tic = time()\n",
    "    env.reset(STARTING_DAYS_AHEAD)\n",
    "    results_list = sim.simulate_period(total_data_in_df, \n",
    "                                       SYMBOL,\n",
    "                                       agents[0],\n",
    "                                       starting_days_ahead=STARTING_DAYS_AHEAD,\n",
    "                                       possible_fractions=POSSIBLE_FRACTIONS,\n",
    "                                       verbose=False,\n",
    "                                       other_env=env)\n",
    "    toc = time()\n",
    "    print('Epoch: {}'.format(i))\n",
    "    print('Elapsed time: {} seconds.'.format((toc-tic)))\n",
    "    print('Random Actions Rate: {}'.format(agents[0].random_actions_rate))\n",
    "    show_results([results_list], data_in_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.reset(STARTING_DAYS_AHEAD)\n",
    "results_list = sim.simulate_period(total_data_in_df, \n",
    "                                   SYMBOL, \n",
    "                                   agents[0], \n",
    "                                   learn=False, \n",
    "                                   starting_days_ahead=STARTING_DAYS_AHEAD,\n",
    "                                   possible_fractions=POSSIBLE_FRACTIONS,\n",
    "                                   other_env=env)\n",
    "show_results([results_list], data_in_df, graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run the trained agent, with the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First a non-learning test: this scenario would be worse than what is possible (in fact, the q-learner can learn from past samples in the test set without compromising the causality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_DAYS_AHEAD = 20\n",
    "\n",
    "env.set_test_data(total_data_test_df, TEST_DAYS_AHEAD)\n",
    "tic = time()\n",
    "results_list = sim.simulate_period(total_data_test_df, \n",
    "                                    SYMBOL,\n",
    "                                    agents[0],\n",
    "                                    learn=False,\n",
    "                                    starting_days_ahead=TEST_DAYS_AHEAD,\n",
    "                                    possible_fractions=POSSIBLE_FRACTIONS,\n",
    "                                    verbose=False,\n",
    "                                    other_env=env)\n",
    "toc = time()\n",
    "print('Epoch: {}'.format(i))\n",
    "print('Elapsed time: {} seconds.'.format((toc-tic)))\n",
    "print('Random Actions Rate: {}'.format(agents[0].random_actions_rate))\n",
    "show_results([results_list], data_test_df, graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now a \"realistic\" test, in which the learner continues to learn from past samples in the test set (it even makes some random moves, though very few)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env.set_test_data(total_data_test_df, TEST_DAYS_AHEAD)\n",
    "tic = time()\n",
    "results_list = sim.simulate_period(total_data_test_df, \n",
    "                                    SYMBOL,\n",
    "                                    agents[0],\n",
    "                                    learn=True,\n",
    "                                    starting_days_ahead=TEST_DAYS_AHEAD,\n",
    "                                    possible_fractions=POSSIBLE_FRACTIONS,\n",
    "                                    verbose=False,\n",
    "                                    other_env=env)\n",
    "toc = time()\n",
    "print('Epoch: {}'.format(i))\n",
    "print('Elapsed time: {} seconds.'.format((toc-tic)))\n",
    "print('Random Actions Rate: {}'.format(agents[0].random_actions_rate))\n",
    "show_results([results_list], data_test_df, graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the metrics for \"holding the position\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Sharpe ratio: {}\\nCum. Ret.: {}\\nAVG_DRET: {}\\nSTD_DRET: {}\\nFinal value: {}'.format(*value_eval(pd.DataFrame(data_test_df['Close'].iloc[STARTING_DAYS_AHEAD:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../data/simple_q_learner.pkl', 'wb') as best_agent:\n",
    "    pickle.dump(agents[0], best_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_env",
   "language": "python",
   "name": "cap_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
